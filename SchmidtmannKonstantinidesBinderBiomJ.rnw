\documentclass[bimj,fleqn]{w-art}
\usepackage{color}  % included for highlighting (04.11.2107 IS)
\usepackage{times}
\usepackage{w-thm}
\usepackage[authoryear]{natbib}
\setlength{\bibsep}{2pt}
\setlength{\bibhang}{2em}
\newcommand{\J}{J\"{o}reskog}
\newcommand{\So}{S\"{o}rbom}
\newcommand{\bcx}{{\bf X}}
\newcommand{\bcy}{{\bf Y}}
\newcommand{\bcz}{{\bf Z}}
\newcommand{\bcu}{{\bf U}}
\newcommand{\bcv}{{\bf V}}
\newcommand{\bcw}{{\bf W}}
\newcommand{\bci}{{\bf I}}
\newcommand{\bch}{{\bf H}}
\newcommand{\bcb}{{\bf B}}
\newcommand{\bcr}{{\bf R}}
\newcommand{\bcm}{{\bf M}}
\newcommand{\bcf}{{\bf F}}
\newcommand{\bcg}{{\bf G}}
\newcommand{\bcs}{{\bf S}}
\newcommand{\bca}{{\bf A}}
\newcommand{\bcd}{{\bf D}}
\newcommand{\bcc}{{\bf C}}
\newcommand{\bce}{{\bf E}}
\newcommand{\ba}{{\bf a}}
\newcommand{\bb}{{\bf b}}
\newcommand{\bc}{{\bf c}}
\newcommand{\bd}{{\bf d}}
\newcommand{\bx}{{\bf x}}
\newcommand{\by}{{\bf y}}
\newcommand{\bz}{{\bf z}}
\newcommand{\bu}{{\bf u}}
\newcommand{\bv}{{\bf v}}
\newcommand{\bh}{{\bf h}}
\newcommand{\bl}{{\bf l}}
\newcommand{\be}{{\bf e}}
\newcommand{\br}{{\bf r}}
\newcommand{\bw}{{\bf w}}
\newcommand{\de}{\stackrel{D}{=}}
\newcommand{\bt}{\bigtriangleup}
\newcommand{\bfequiv}{\mbox{\boldmath $\equiv$}}
\newcommand{\bmu}{\mbox{\boldmath $\mu$}}
\newcommand{\bnu}{\mbox{\boldmath $\nu$}}
\newcommand{\bxi}{\mbox{\boldmath $\xi$}}
\newcommand{\btau}{\mbox{\boldmath $\tau$}}
\newcommand{\bgamma}{\mbox{\boldmath $\Gamma$}}
\newcommand{\bphi}{\mbox{\boldmath $\Phi$}}
\newcommand{\bfphi}{\mbox{\boldmath $\varphi$}}
\newcommand{\bfeta}{\mbox{\boldmath $\eta$}}
\newcommand{\bpi}{\mbox{\boldmath $\Pi$}}
\newcommand{\bequiv}{\mbox{\boldmath $\equiv$}}
\newcommand{\bvarepsilon}{\mbox{\boldmath $\varepsilon$}}
\newcommand{\btriangle}{\mbox{\boldmath $\triangle$}}
\newcommand{\bdelta}{\mbox{\boldmath $\Delta$}}
\newcommand{\beps}{\mbox{\boldmath $\epsilon$}}
\newcommand{\btheta}{\mbox{\boldmath $\theta$}}
\newcommand{\balpha}{\mbox{\boldmath $\alpha$}}
\newcommand{\bsphi}{\mbox{\boldmath $\varphi$}}
\newcommand{\bsig}{\mbox{\boldmath $\sigma$}}
\newcommand{\bfpsi}{\mbox{\boldmath $\psi$}}
\newcommand{\bfdelta}{\mbox{\boldmath $\delta$}}
\newcommand{\bsigma}{{\bf \Sigma}}
\newcommand{\bzero}{{\bf 0}}
\newcommand{\bpsi}{\mbox{\boldmath $\Psi$}}
\newcommand{\bep}{\mbox{\boldmath $\epsilon$}}
\newcommand{\bomega}{\mbox{\boldmath $\Omega$}}
\newcommand{\bfomega}{\mbox{\boldmath $\omega$}}
\newcommand{\blambda}{\mbox{\boldmath $\Lambda$}}
\newcommand{\bflambda}{\mbox{\boldmath $\lambda$}}
\newcommand{\bfsigma}{\mbox{\boldmath $\sigma$}}
\newcommand{\bfpi}{{\mbox{\boldmath $\pi$}}}
\newcommand{\bupsilon}{\mbox{\boldmath $\upsilon$}}
\newcommand{\obs}{{\rm obs}}
\newcommand{\mis}{{\rm mis}}
\theoremstyle{plain}
\newtheorem{criterion}{Criterion}
\theoremstyle{definition}
\newtheorem{condition}[theorem]{Condition}
\usepackage[]{graphicx}
\chardef\bslash=`\\ % p. 424, TeXbook
\newcommand{\ntt}{\normalfont\ttfamily}
\newcommand{\cn}[1]{{\protect\ntt\bslash#1}}
\newcommand{\pkg}[1]{{\protect\ntt#1}}
\let\fn\pkg
\let\env\pkg
\let\opt\pkg
\hfuzz1pc % Don't bother to report overfull boxes if overage is < 1pc
\newcommand{\envert}[1]{\left\lvert#1\right\rvert}
\let\abs=\envert

\begin{document}
% initial chunk that loads necessary libraries and functions
<<init, include=FALSE>>=
# load all libraries and functions
library(knitr)
library(xtable)
library(latex2exp)


# ------------------------------------------------------------------------------
# function moments computes mean and variance of Wilcoxon-Mann-Whitney statistic
# in the presence of death-censored observations
# ------------------------------------------------------------------------------
# Assumptions:
# - normal one-sided test for difference $\epsilon = 0$
# - non-inferiority margin $\epsilon > 0$

# it returns $\mu_u$ and $\sigma_u$

# function parameters
# $p_0 = p_0$, probability of censoring by death in reference group \\
# $p_1 = p_1$, probability of censoring by death in treatment group\\
# $\mu_0_0 = \mu_0$, mean in reference group \\
# $\mu_1_0 = \mu_1$, mean in treatment group \\
# $\sigma =  var(X_i), i=0, 1$ \\
# $\tau$ = time when quantitative endpoint is determined, this is needed to calculate
# the hazards \\
# $n_0 = $ sample size in reference group \\
# $n_1 = $ sample size in treatment group \\
# verbose = TRUE / FALSE controls output
# tied = TRUE / FALSE determines whether untied or tied version should be computed
# ------------------------------------------------------------------------------

moments <- function(p_0 = 0.2, p_1 = 0.3, mu_0 = 1, mu_1 = 1, sigma = 1, tau = 1,
                    n_0 = 50, n_1 = 50, verbose = FALSE, tied = FALSE){
  q_0 <- 1 - p_0
  q_1 <- 1 - p_1
  # pi_t1, pi_t2 and pi_t3 are only needed in the untied case
  if (!tied) {
    # Non-null mortality risk in both groups
    if (p_0 > 0 && p_1 > 0) {
      lambda_0 <- -log(q_0) / tau
      lambda_1 <- -log(q_1) / tau
      HR <- lambda_1 / lambda_0
      pi_t1 <- (p_0 * (p_1  - 1) * HR / (1 + HR) + p_1 / (1 + HR)) / (p_0 * p_1)
      pi_t2 <- (p_1 - 2 * HR / (1 + HR) * (1 - q_0 * q_1) + (1 - q_0^2 * q_1) * HR / (2 + HR) ) / (p_0^2 * p_1)
      pi_t3 <- (p_0 * q_1^2 + 2 * q_1 * (q_0 * q_1 - 1) / (1 + HR) - (q_0 * q_1^2 - 1) / (1 + 2*HR)) / (p_0 * p_1^2)
      if (verbose) {
        print(paste0("HR = ", HR))
        print(paste0("pi_t1 = ", pi_t1))
        print(paste0("pi_t2 = ", pi_t2))
        print(paste0("pi_t3 = ", pi_t3))
      }
    } else{
      # if there is no mortality risk in at least one group then the terms with
      # pi_t1, pi_t2, and pi_t3 vanish, i. e.
      pi_t1 <- 0
      pi_t2 <- 0
      pi_t3 <- 0
    }
  }
  delta <- mu_1 - mu_0
  shift <- delta / sigma
  if (verbose) {
    print(paste0("delta = ", delta))
    print(paste0("shift = ", shift))
  }

  integrand1 <- function(x) {
    return(dnorm(x - shift)*pnorm(x))
  }
  integrand2 <- function(x) {
    return(dnorm(x - shift)*(pnorm(x))^2)
  }

  integrand3 <- function(x) {
    return(dnorm(x)*(pnorm(x - shift))^2)
  }

  pi_x1 <- integrate(integrand1, -Inf, Inf)$value
  pi_x2 <- integrate(integrand2, -Inf, Inf)$value
  pi_x3 <- 2*pi_x1 - 1 + integrate(integrand3, -Inf, Inf)$value

  if (verbose) {
    print(paste0("pi_x1 = ", pi_x1))
    print(paste0("pi_x2 = ", pi_x2))
    print(paste0("pi_x3 = ", pi_x3))
  }
  if (!tied) {
    pi_u1 <- p_0 * p_1 * pi_t1 + p_0 * q_1 + q_0 * q_1 * pi_x1
    pi_u2 <- p_0^2 * q_1 + p_0^2 * p_1 * pi_t2 + 2 * p_0 * q_0 * q_1 * pi_x1 + q_0^2 * q_1 * pi_x2
    pi_u3 <- p_0 * q_1^2 + p_0 * p_1^2 * pi_t3 + 2 * p_0 * p_1 * q_1 * pi_t1 + q_0 * q_1^2 * pi_x3
  }else{
    pi_u1 <- p_0 * p_1 / 2 + p_0 * q_1 + q_0 * q_1 * pi_x1
    pi_u2 <- p_0^2 * q_1 + p_0^2 * p_1 / 3 + 2 * p_0 * q_0 * q_1 * pi_x1 + q_0^2 * q_1 * pi_x2
    pi_u3 <- p_0 * q_1^2 + p_0 * p_1^2 / 3 + p_0 * p_1 * q_1  + q_0 * q_1^2 * pi_x3
  }
  if (verbose) {
    print(paste0("pi_u1 = ", pi_u1))
    print(paste0("pi_u2 = ", pi_u2))
    print(paste0("pi_u3 = ", pi_u3))
  }

  mu_u <- pi_u1
  if (!tied) {
    sigma_u <- sqrt((pi_u1 * (1 - pi_u1) + (n_0 - 1)*(pi_u2 - pi_u1^2) + (n_1 - 1)*(pi_u3 - pi_u1^2)) / (n_0 * n_1) )
  }else{
    sigma_u <- sqrt((pi_u1 * (1 - pi_u1) + (n_0 - 1)*(pi_u2 - pi_u1^2 - p_0^2 * p_1 / 12)
                                         + (n_1 - 1)*(pi_u3 - pi_u1^2 - p_0 * p_1^2 / 12) - p_0 * p_1 / 4) / (n_0 * n_1) )
  }
  if (verbose) {
    print(paste0("mu_u = ", mu_u))
    print(paste0("sigma_u = ", sigma_u))
  }
  list(mu_u, sigma_u)
  return(list(mu_u = mu_u, sigma_u = sigma_u))
}

# ------------------------------------------------------------------------------
# Function power_gr determines power for the Wilcoxon-Mann-Whitney test for non-inferiority in
# the presence of death-censored observations
# ------------------------------------------------------------------------------
# Assumptions
# - normal one-sided test for difference $\epsilon = 0$
# - non-inferiority margin $\epsilon > 0$

# epsilon is computed from \mu_0$ under $H_0$
# $H_0: \mu(U) = P(\tilde{X_{0k}} < \tilde{X_{1l}}) \leq \frac{1}{2} - \epsilon$ \\
# $H_1: \mu(U) = P(\tilde{X_{0k}} < \tilde{X_{1l}}) > \frac{1}{2} - \epsilon $ \\

# Function parameters.
# $p_0_0 = p_0$ under $H_0$ (probability of censoring by death in reference group under $H_0$) \\
# $p_1_0 = p_1$ under $H_0$ (probability of censoring by death in treatment group under $H_0$) \\
# $p_0_1 = p_0$ under $H_1$ (probability of censoring by death in reference group under $H_1$) \\
# $p_1_1 = p_1$ under $H_1$ (probability of censoring by death in treatment group under $H_1$) \\
# $\mu_0_0 = \mu_0$ under $H_0$ (mean in reference group under $H_0$) \\
# $\mu_1_0 = \mu_1$ under $H_0$ (mean in treatment group under $H_0$) \\
# $\mu_0_1 = \mu_0$ under $H_1$ (mean in reference group under $H_1$) \\
# $\mu_1_1 = \mu_1$ under $H_1$ (mean in treatment group under $H_1$) \\
# $\sigma =  var(X_i), i=0, 1$ under $H_0$ and $H_1 $ \\
# $\tau$ = time when quantitative endpoint is determined, this is needed to calculate
# the hazards \\
# $n_0 = $ sample size in reference group \\
# $n_1 = $ sample size in treatment group \\
# verbose = TRUE / FALSE controls output
# tied = TRUE / FALSE determines whether untied or tied version should be computed

power_gr <- function(alpha,
                     p_0_0 = 0.2, p_1_0 = 0.2, p_0_1 = 0.2, p_1_1 = 0.2,
                     mu_0_0 = 1, mu_1_0 = 1, mu_0_1 = 1, mu_1_1 = 1,
                     sigma = 1, tau = 1,
                     n_0 = 50, n_1 = 50, verbose = FALSE, tied = FALSE){
  # determine moments unter $H_0$
  moments_H_0 <- moments(p_0 = p_0_0, p_1 = p_1_0, mu_0 = mu_0_0, mu_1 = mu_1_0,
                         sigma = sigma, tau = tau, n_0 = n_0, n_1 = n_1,
                         verbose = verbose, tied = tied)
  # compute effective epsilon, given parameters under $H_0$
  epsilon <- 0.5 - moments_H_0$mu_u

  if (verbose) {
    print("moments unter H_0")
    print(paste0("mu_u_0 = ", moments_H_0$mu_u))
    print(paste0("sigma_u_0 = ", moments_H_0$sigma_u))
  }
  # determine moments unter $H_1$
  moments_H_1 <- moments(p_0 = p_0_1, p_1 = p_1_1, mu_0 = mu_0_1, mu_1 = mu_1_1,
                         sigma = sigma, tau = tau, n_0 = n_0, n_1 = n_1, verbose = verbose)
  if (verbose) {
    print("moments unter H_1")
    print(paste0("mu_u_1 = ", moments_H_1$mu_u))
    print(paste0("sigma_u_1 = ", moments_H_1$sigma_u))
  }
  # compute $1 - \alpha$ percentile of the standard normal distribution
  z_alpha <- qnorm(alpha, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
  power = pnorm((z_alpha * moments_H_0$sigma_u  + moments_H_1$mu_u - moments_H_0$mu_u) / moments_H_1$sigma_u)
  list(power, epsilon)
  return(list(power = power, epsilon = epsilon))
}

# set global chunk options
opts_chunk$set(warning = FALSE, message = FALSE)
@
%\DOIsuffix{bimj.DOIsuffix}
\DOIsuffix{bimj.200100000}
\Volume{52}
\Issue{61}
\Year{2010}
\pagespan{1}{}
\keywords{Censoring by death; Global rank test; Non-inferiority; Combined endpoints; Pulmonary embolism;\\
\noindent\hspace*{-4.2pc} Supporting Information for this article is available on the WWW under\break \hspace*{-4pc} \underline{https://github.com/IreneSchmidtmann/GlobalRankTest}
}  %%% semicolon and fullpoint added here for keyword style

\title[Non-inferiority test death censored]{Power of the Wilcoxon-Mann-Whitney test for non-inferiority in the presence of death-censored observations}
%% Information for the first author.
\author[Schmidtmann]{Irene Schmidtmann\footnote{Corresponding author: {\sf{e-mail: Irene.Schmidtmann@uni-mainz.de}}, Phone: +49-6131-173951, Fax: +49-6131-172968}\inst{,1}}
\address[\inst{1}]{Institute for Medical Biostatistics, Epidemiology and Informatics (IMBEI),
University Medical Center Johannes Gutenberg University Mainz, D 55101 Mainz}
%%%%    Information for the second author
\author[Konstantinides]{Stavros Konstantinides\inst{2}}
\address[\inst{2}]{Center for Thrombosis and Hemostasis (CTH), University Medical Center Johannes Gutenberg University Mainz, D 55101 Mainz}
%%%%    Information for the third author
\author[Binder]{Harald Binder\inst{3}}
\address[\inst{3}]{Institute of Medical Biometry and Statistics, Medical Faculty and Medical Center -- University Freiburg, Stefan-Meier-Str. 26, D 79104 Freiburg}
%%%%    \dedicatory{This is a dedicatory.}
\Receiveddate{zzz} \Reviseddate{zzz} \Accepteddate{zzz}

\begin{abstract}
In clinical trials with patients in a critical state, death may preclude
measurement of a quantitative endpoint of interest, and even early measurements,
e.g. for intention-to-treat analysis, may not be available. For example, a
non-negligible proportion of patients with acute pulmonary embolism will die,
before 30 day measurements on the efficacy of thrombolysis can be obtained. As
excluding such patients may introduce bias, alternative analyses and
corresponding means for sample size calculation are needed. We specifically,
consider power analysis in a randomized clinical trial setting in which the goal
is to demonstrate non-inferiority of a new treatment as compared to a reference
treatment. Also, a non-parametric approach is needed due to the distribution of
the quantitative endpoint of interest. While some approaches have been developed
in a composite endpoint setting, our focus is on the continuous endpoint, and
also no approach for non-inferiority is available. We propose a solution based
on ranking the quantitative outcome and assigning “worst rank” scores to the
patients without quantitative outcome because of death. Based on
this, we derive power formulae for a non-inferiority test in the presence of
death-censored observations, considering settings with and without ties. The
approach is illustrated for an examplary clinical trial in pulmonary embolism.
The results there show a substantial effect of death on power, also depending on
differential effects in the two trial arms. Therefore, use of the proposed
formulae is advisable whenever there is death to be expected before measurment
of a quantiative primary outcome of interest.
\end{abstract}



%% maketitle must follow the abstract.
\maketitle                   % Produces the title.

%% If there is not enough space inside the running head
%% for all authors including the title you may provide
%% the leftmark in one of the following three forms:

%% \renewcommand{\leftmark}
%% {First Author: A Short Title}

%% \renewcommand{\leftmark}
%% {First Author and Second Author: A Short Title}

%% \renewcommand{\leftmark}
%% {First Author et al.: A Short Title}

%% \tableofcontents  % Produces the table of contents.


\section{Introduction}
\label{sec:Intro}

In clinical trials for cardiovascular diseases, often the aim of an
intervention is to improve functional capacity, measured by some quantitative
surrogate endpoint such as the six minute walking distance, a biomarker levels,
or echocardiographic parameters of cardiovascular function.

Typically, unfavourable outcomes of the quantitative endpoint are related to a
higher risk of cardiovascular deat and consequently there is a non-negligible
probability of an early fatal outcome. Thus, censoring by
death may occur if a patient dies before the quantitative outcome can be
determined. Censoring by death leads to missing values which are most unlikely
to be missing at random. Therefore, ignoring and excluding this kind of
missing values from analysis does not only decrease power but may also lead to
biased estimates of treatment effect. It also contradicts the
intention-to-treat principle when not all patients included in the trial are
included in the analysis.

Worst-rank scores have been considered e. g. by Wittes et al (1989) and Lachin
(1999) to tackle this problem. Without loss of generality we assume that
higher values of the quantitative outcome are more favourable than lower
values. We further assume that any quantitative outcome is better than death
and that earlier death is worse than later death. This leads to an obvious
ordering of outcomes which motivates the definition of worst-rank scores.

Tied worst-rank scores are obtained by allocating a rank score corresponding
to a single value below the minimum observed value of the quantitative
endpoint. Untied worst-rank scores can be obtained, if the time of death is
taken into account. The lowest rank score is then allocated to the patient
that has died first, subsequent deceased individuals receive ranks according
to their time of death. After the deceased have been ranked, the subsequent
ranks are allocated to the surviving patients according to their quantitative
outcome.

Lachin (1999) has shown that such an approach is unbiased against a restricted
one-sided alternative which states that the new treatment is better with
respect to both, mortality and the quantitative endpoint or at least better
with respect to one criterion and equal with respect to the other.

Another view of this approach is to consider it as a global ranking of
multiple endpoints, e. g. some kind of event - such as death - and some
quantitative measurement - such as a biomarker. This approach was originally
suggested by O'Brien (1984) for multiple endpoints and applied in cardiology
e. g. by Felker at al (2008) and Felker and Maisel (2010) combining several
binary and quantitative endpoints.

We here consider the situation where a new treatment is compared to a standard
treatment and the intention is to show that the new treatment is non-inferior
to the standard treatment when comparing a quantitative measurement that may
be censored by death. As above this corresponds to a one-sided hypothesis.
The alternative hypothesis in this case states that the new treatment is
non-inferior to the standard treatment with respect to both the quantitative
endpoint and the mortality risk.

Matsouaka and Bentensky (2015) have derived power and sample size formulae for
the one-sided test of the null hypothesis of equality against a restricted
alternative as described by Lachin (1999). They present specific formulae for
common distributions of quantitative endpoint and time to event, amongst them
a normally distributed quantitative endpoint and exponentially distributed
time to event.

However, to the best of our knowledge, so far no power or sample size formula
for the Wilcoxon-Mann-Whitney test for non-inferiority in the presence of
death-censored observations is available.

In section section~\ref{sec:ThrombolysisApplication}, we present the
application, a clinical trial in pulmonary embolism, that motivated our
methodological work. After setting out the notation in section
~\ref{sec:Notation}, the power formulae are derived in section ~\ref{sec:Power}.
Section ~\ref{sec:Application} illustrates the application of the derived
formulae to the planned clinical trial. A discussion and concluding remarks
are provided in Section ~\ref{sec:Discussion}.


\section{Thrombolysis application}
\label{sec:ThrombolysisApplication}
The methodological considerations presented in this paper were motivated by
planning a clinical trial studying treatment of patients with
intermediate-high-risk pulmonary embolism. These are patients who are
normotensive and appear hemodynamically stable at presentation, but have
evidence of right ventricular dysfunction on echocardiography in addition to
elevated cardiac troponin levels in the circulation.

In this trial, the standard would be to administer standard-dose systemic
thrombolytic treatment. The new experimental treatment would be catheter-directed,
ultrasound-assisted low dose thrombolysis. The right to left ventricular (RV/LV)
diameter ratio on echocardiography 24 hours after the intervention was
considered a suitable primary endpoint. Unfortunately, fatal
outcomes do occur within hours after treatment in patients with this condition.
This precludes the observation of the RV/LV diameter ratio 24 hours after the
intervention. Therefore, taking into account censoring by death of the
quantitative endpoint was necessary.

While little difference in the primary endpoint and mortality was expected,
the potential benefit of the low dose thrombolysis would be lower bleeding
risk. Therefore, as primary endpoint analysis, we chose to test for
non-inferiority and to apply a Wilcoxon-Mann-Whitney test for non-inferiority
in the presence of death-censored observations.

\section{Notation and hypotheses}
\label{sec:Notation}
Let the quantitative endpoint be determined at time $\tau (\tau > 0)$. Let
further $X_{01}, \ldots, X_{0n_0}$ denote the values of the quantitative endpoint
in the $n_0$ indiviudals in the reference group with standard treatment ($i=0$)
and $X_{11}, \ldots, X_{1n_1}$ the values of the quantitative endpoint in the
$n_1$ indiviudals in thegroup with the new experimental treatment ($i=1$).
The event times in group $i$ are given by $T_{i1}, \ldots, T_{in_i}$. Let
$D_{ik} = 1$ indicate that subject $k$ in group $i$ dies before the
quantitative endpoint $X_{ik}$ can be determined, i. e. $D_{ik} = 1$ if
$T_{ik} < \tau $, $D_{ik} = 0$ otherwise. The survival probability in group
$i$ up to time $\tau$ is given by $q_i = S_i(\tau)$, where $S(t)$ is the survival function.
  Accordingly, the cumulative mortality in group $i$ up to time $\tau$ is given by
$p_i = 1 - q_i = \text{P}(D_{ik} = 1)$.

Here, without loss of generality, we assume that high values of $X_{ik}$ are
favourable. Otherwise we could consider $-X_{ik}$. We further assume that
death is worse than any quantitative outcome and -- in the untied worst rank
case -- that early death is worse thant later death.

Following Matsouaka and Betensky (2015), we introduce a new variable, on which
  ranking can be based. This variable is constructed such that all patients who
  die before time $\tau$ have lower values than the patients who survive past
  $\tau$ and are ranked according to their survival times. Patients who survive
  past time $\tau$ are ranked according to their observed value of the quantitative
  endpoint. The new variable is defined as
  $\widetilde{X}_{ik} = D_{ik}(\eta  + T_{ik}) + (1 - D_{ik})X_{ik}$ with
  $\eta = \min(X_{01}, \ldots, X_{0n_0}, X_{11}, \ldots, X_{1n_1}) - 1 - \tau$
  in the untied case.  In the tied case all patients who die before the quantitative endpoint
  can be determined have the same rank. Hence, a different definition of $\widetilde{X}_{ik}$
  is needed and we set  $\widetilde{X}_{ik} = D_{ik}\zeta   + (1 - D_{ik})X_{ik}$
  with $\zeta = \min(X_{01}, \ldots, X_{0n_0}, X_{11}, \ldots, X_{1n_1}) - 1$.
  Note, that  $\widetilde{X}_{ik} = {X}_{ik}$ holds for patient who survive past $\tau$ in both cases.

  The non-inferiority hypotheses are
\begin{align*}
  H_0 &:  \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l})
          \leq \frac{1}{2} - \varepsilon \\
H_1 &:  \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l})
          > \frac{1}{2} - \varepsilon
\end{align*}

with non-inferiority margin $\varepsilon > 0$ for any pair $(k, l)$ of
observations from the two treatment groups.

\section{Power calculation}
\label{sec:Power}
\subsection{Untied case}
\label{sec:PowerUntied}
The $\widetilde{X}_{ik}$ as defined in section~\ref{sec:Notation} are used to
  determine ranks and to compute the Wilcoxon-Mann-Whitney test statistic
  $ U =(n_0 n_1)^{-1}(\sum_{k=1}^{n_0}
    \sum_{l=1}^{n_1}I(\widetilde{X}_{0k} < \widetilde{X}_{1l})) $.

  In order to evaluate the power of the Wilcoxon-Mann-Whitney test, we use the
standardised version of the Wilcoxon-Mann-Whitney U statistic, i. e. the test
  statistic is given by $U^* =(U - \mu_0(U)) / \sigma_0(U)$, where $\mu_0(U)$ is the
  expectation and $\sigma^2_0(U)$ the variance of U under the null hypothesis.
  Then under the null hypothesis $U^*$ asymptotically follows a standard normal
  distribution. The null hypothesis is rejected at level $\alpha$ if
  $U^* > z_{1 - \alpha}$ where
$z_{1-\alpha} = \Phi^{-1}({1-\alpha})$ is the $(1 - \alpha)$-percentile of the
normal distribution.

  Therefore we need expectation $\mu(U)$ and variance $\sigma^2(U)$ of U. They
  were derived by Matsouaka and Betensky (2015) and are as follows:
\begin{align*}
\mu(U) &= \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l}) \mbox{ for arbitrary }
               \widetilde{X}_{0k}, \widetilde{X}_{1l} \\
       &= p_0 p_1 \pi_{t1} + p_0 q_1 + q_0 q_1 \pi_{x1} \\
       &= \pi_{U1}
\intertext{with}
\pi_{X1} &= \text{P}(X_{0k} < X_{1l}) \\
\pi_{T1} &= \text{P}(T_{0k} < T_{1l} | D_{0k} = D_{1l} = 1) \\
\sigma^2(U) &= (n_0 n_1)^{-1} \left\{ \pi_{U1} (1 - \pi_{U1}) +
                                  (n_0 - 1) (\pi_{U2} - \pi_{U1}^2) +
                                  (n_1 - 1) (\pi_{U3} - \pi_{U1}^2) \right\}
\intertext{with}
\pi_{U2} &= \text{P}(\widetilde{X}_{0k'} < \widetilde{X}_{1l}, \widetilde{X}_{0k'} < \widetilde{X}_{1l}) \\
         &= p_0^2 q_1 + p_0^2 p_1 \pi_{t2} + 2 p_0 q_0 q_1 \pi_{x1} + q_0^2 q_1 \pi_{x2} \\
\pi_{X2} &= \text{P}(X_{0k} < X_{1l}, X_{0k'} < X_{1l}) \\
\pi_{T2} &= \text{P}(T_{0k} < T_{1l}, T_{0k'} < T_{1l} | D_{0k} = D_{0k'} = D_{1l} = 1) \\
\pi_{U3} &= \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l}, \widetilde{X}_{0k} < \widetilde{X}_{1l'}) \\
         &= p_0 q_1^2 + p_0 p_1^2 \pi_{t3} + 2 p_0 p_1 q_1 \pi_{t1} + q_0 q_1^2 \pi_{x3} \\
\pi_{X3} &= \text{P}(X_{0k} < X_{1l}, X_{0k} < X_{1l'}) \\
\pi_{T3} &= \text{P}(T_{0k} < T_{1l}, T_{0k} < T_{1l'} | D_{0k} = D_{1l} = D_{1l'} =1)\\
         &{\hphantom{=}}  \mbox{ for arbitrary } \widetilde{X}_{0k}, \widetilde{X}_{0k'}, \widetilde{X}_{1l},
                                     \widetilde{X}_{1l'}, k \ne k', l \ne l'
\end{align*}

If assumptions about the distribution of quantitative endpoint and event time
are made, $\mu(U)$ and $\sigma(U)$ can be computed. When determining the power,
we consider the boundary of the null hypothesis, i. e.
$\mu_0(U) = \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l}) = 1/2 - \varepsilon$.
The power of the test for a specific alternative, where $\mu(U)) = \mu_1(U))$
and $\sigma(U) = \sigma_1(U)$, is given by
\begin{align*}
  1 - \beta &= \text{P} \left(\frac{U - \mu_0(U)}{\sigma_0(U)}  >
                                 z_{1-\alpha} \mid H_1 \right) \\
            &= \text{P} \left(\frac{U - \mu_1(U)}{\sigma_1(U)}  >
                                 z_{1-\alpha}\frac{\sigma_0(U)}{\sigma_1(U)} +
                                 \frac{\mu_0(U) - \mu_1(U)}{\sigma_1(U)} \right) \\
            &= \Phi\left(- z_{1-\alpha}\frac{\sigma_0(U)}{\sigma_1(U)} -
                            \frac{\mu_0(U) - \mu_1(U)}{\sigma_1(U)} \right) \\
            &= \Phi\left(z_{\alpha}\frac{\sigma_0(U)}{\sigma_1(U)} +
                            \frac{\mu_1(U) - \mu_0(U)}{\sigma_1(U)} \right) .
\end{align*}

If the specific alternative considered is equivalence of treatments, i. e.
$\widetilde{X}_{0k}$ and $\widetilde{X}_{1l}$ are from the same distribution,
we have $\mu_1(U) = \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l}) = 1/2$
and $\sigma^2_1(U) = (n_0 + n_1 +1) /12 n_0 n_1$. The power is
then given by
\begin{align*}
1 - \beta &= \Phi\left(z_{\alpha}\frac{\sigma_0(U)}{\sigma_1(U)} +
                            \frac{\varepsilon}{\sigma_1(U)} \right) \\
          &= \Phi\left(z_{\alpha} \sqrt{\frac{12 \big\{ \pi_{U1} (1 - \pi_{U1}) +
                                  (n_0 - 1) (\pi_{U2} - \pi_{U1}^2) +
                                  (n_1 - 1) (\pi_{U3} - \pi_{U1}^2) \big\}}{n_0 + n_1 +1}} \right.\\
          &{\hphantom{= \Phi\bigg(}} \left. + \varepsilon \sqrt{\frac{12 n_0 n_1 }{n_0 + n_1 +1}} \right) .
\end{align*}

\subsection{Tied case}
\label{sec:PowerTied}
In the tied case we use the modified Wilcoxon-Mann-Whitney statistic $ \widetilde{U}$
which allows for ties and is defined as
$ \widetilde{U} =(n_0 n_1)^{-1}\sum_{k=1}^{n_0}
  \sum_{l=1}^{n_1}\left\{I(\widetilde{X}_{0k} < \widetilde{X}_{1l})
  + I(\widetilde{X}_{0k} = \widetilde{X}_{1l}) / 2 \right\} $.
As before, for determining the power the standardised version of the test statistic
is used:
$\widetilde{U}^* = (\widetilde{U} - \mu_0(\widetilde{U} )) / \sigma_0(\widetilde{U}) $
where
$\mu_0(\widetilde{U})$ is the expectation and $\sigma^2_0(\widetilde{U})$ the variance
of $\widetilde{U}$ under the null hypothesis. Under the null hypothesis $\widetilde{U}^*$
also follows a standard normal distribution. Again, the null hypothesis is rejected at
if level $\alpha$ if $\widetilde{U}^* > z_(1-\alpha).$

Matsouaka and Betensky (2015) also derived expectation and variance in the tied case which
are as follows:

\begin{align*}
  \mu(\widetilde{U}) &= \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l})
                        + \text{P}(\widetilde{X}_{0k} = \widetilde{X}_{1l}) / 2
                        \mbox{ for arbitrary }
                         \widetilde{X}_{0k}, \widetilde{X}_{1l} \\
                     &= \frac{p_0 p_1}{2}  + p_0 q_1 + q_0 q_1 \pi_{x1} \\
                     &= \pi_{\widetilde{U}1} \\
  \sigma^2(\widetilde{U}) &= (n_0 n_1)^{-1}
                             \left\{ \pi_{\widetilde{U}1} (1 - \pi_{\widetilde{U}1}) +
                             (n_0 - 1) \left(\pi_{\widetilde{U}2} - \pi_{\widetilde{U}1}^2  - \frac{p^2_0 p_1}{12} \right)
                             \right.\\
                          &\hphantom{(n_0 n_1)^{-1} left\{ }
                          \left.
                            + (n_1 - 1) \left(\pi_{\widetilde{U}3} - \pi_{\widetilde{U}1}^2  - \frac{p_0 p^2_1}{12}\right)
                            - \frac{p_0 p_1}{4}\right\}
  \intertext{with}
  \pi_{\widetilde{U}2} &= p^2_0 q_1 + \frac{p^2_0 p_1}{3} + 2 p_0 q_0 q_1 \pi_{X1} + q^2_0 q_1 \pi_{X2} \\
  \pi_{\widetilde{U}3} &= p_0 q^2_1 + \frac{p_0 p^2_1}{3} + p_0 p_1 q_1 + q_0 q^2_1 \pi_{X3}
                          \mbox{, where } \pi_{X1}, \pi_{X2}, \pi_{X3} \mbox{ are as in the untied case.}
\end{align*}

Again, $\mu(\widetilde{U})$ and $\sigma(\widetilde{U})$ under the null
hypothesis or under the alternative can be computed if assumptions about the
distributions of quantitative endpoint and event time are made. As previously, we
consider the boundary of the null hypothesis, i. e.
$\mu_0(\widetilde{U}) = \text{P}(\widetilde{X}_{0k} <
\widetilde{X}_{1l}) = \frac{1}{2} - \varepsilon$ when assessing the power of
the test. The power is given by

\begin{align*}
  1 - \beta &= \text{P} \left(\frac{\widetilde{U} - \mu_0(\widetilde{U})}{\sigma_0(\widetilde{U})}  >
                                 z_{1-\alpha} \mid H_1 \right) \\
            &= \Phi\left(z_{\alpha}\frac{\sigma_0(\widetilde{U})}{\sigma_1(\widetilde{U})} +
                            \frac{\mu_1(\widetilde{U}) - \mu_0(\widetilde{U})}{\sigma_1(\widetilde{U})} \right)
\end{align*}

If the specific alternative considered is equivalence of treatments, i. e.
$\widetilde{X}_{0k}$ and $\widetilde{X}_{1l}$ are from the same distribution,
we have $p_0 = p_1 = p, q_0 = q_1 = q, \pi_{X1} = 1/2,
\pi_{X2} = \pi_{X3} = 1/3$ and hence
$\pi_{\widetilde{U}1} = 1/2, \pi_{\widetilde{U}2} = \pi_{\widetilde{U}3} = 1/3 $.
Consequently, $\mu_1(\widetilde{U}) = \text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l}) = 1/2$
and \\
$\sigma^2_1(\widetilde{U}) = \left\{ (n_0 + n_1 +1) -
              p^2 \left[ 3 +(n_0 + n_1 -2) p \right] \right\} / (12 n_0 n_1)$.\\
The power is then given by

\begin{align*}
  1 - \beta &= \Phi\left(z_{\alpha}\frac{\sigma_0(\widetilde{U})}{\sigma_1(\widetilde{U})} +
                          \frac{\varepsilon}{\sigma_1(\widetilde{U})} \right) \\
            &= \textstyle{\Phi\left(z_{\alpha}
               \sqrt\frac{
               \left\{ \pi_{\widetilde{U}1} (1 - \pi_{\widetilde{U}1})
                     + (n_0 - 1)( \pi_{\widetilde{U}2} - \pi^2_{\widetilde{U}1} - \frac{p_0^2 p_1}{12})
                     + (n_1 - 1)( \pi_{\widetilde{U}3} - \pi^2_{\widetilde{U}1} - \frac{p_0 p_1^2}{12})
                     - \frac{p_0 p_1}{4}
              \right\}}{\left\{ (n_0 + n_1 +1) -
              p^2 \left[ 3 +(n_0 + n_1 -2) p \right] \right\} / 12 } \right.} \\
            &{\hphantom{= \Phi\bigg(}} + \left.
            \varepsilon \sqrt\frac{12}{(n_0 + n_1 +1) -
              p^2 \left[ 3 +(n_0 + n_1 -2) p \right]} \right)
\end{align*}


\section{Application}
\label{sec:Application}
  For the clinical application we assume that the RV/LV reduction is approximately normally distributed
with common variance for both treatment groups:
$X_i \sim \mathcal{N} ( \mu_i, \sigma^2 ), (i = 0, 1)$. Under the standard treatment RV/LV reduction
is expected to be $\mu_0 = 0.3$ on average with standard deviation $\sigma= 0.1$. A difference of
$\varepsilon^{*} = 0.05 = 0.5 \sigma$ is deemed acceptable. This would be used as non-inferiority
margin in a parametric test if no censoring by death occurred. The corresponding parametric hypotheses
are $H_0: \mu_1 \leq \mu_0 - \epsilon^{*}  = \mu_0 - 0.5 \sigma $ and
$H_1: \mu_1 > \mu_0 - \epsilon^{*} = \mu_0 - 0.5 \sigma $ with $\mu_0 = 0.3$ and $\sigma = 0.1$.
We chose $\alpha = 0.0294$ as one interim analysis is planned in a Pocock group sequential design.
We explore the power as a function of sample size and the probabilities of death in
both treatment groups for the specific alternative of equivalence of treatments.
The ratio of $n_0 : n_1$ is chosen as $1 : 2 $ in our application.

In a first step we determine the non-parametric non-inferiority margin $\tilde{\epsilon}$
for the case of no censoring by death such that
$H_0: P(X_0 < X_1) \leq \frac{1}{2} - \tilde{\epsilon}$ and
$H_1: P(X_0 < X_1) >  \frac{1}{2} - \tilde{\epsilon}$.

 As $\Phi(x)$ is monotonically increasing and under $H_0$ we have
 $P(X_0 < X_1) = \Phi((\mu_1 - \mu_0)/\sqrt{2}\sigma) \leq \Phi(\epsilon^{*}/ \sqrt{2}\sigma) = \Phi(-1/\sqrt{8}) $,
 $\tilde{\epsilon}$ can be chosen such that
 $1/2 - \tilde{\epsilon} = \Phi(-1/\sqrt{8}) $ and hence
 $\tilde{\epsilon} = 1/2 - \Phi(-1/\sqrt{8})  \approx $ \Sexpr{round(0.5 - pnorm(-1/sqrt(8)), 4)}.

All calculations were performed using {\tt{R 3.4.2}}, packages {\tt{knitr, xtable, latex2exp}}.

\subsection{Untied case}
\label{sec:AppUntied}
For the untied case we assume that the time to death follows an exponential distribution, i. e.
$T_i \sim exp(\lambda_i), (i=0,1)$, i. e. $q_i = exp(-\lambda_i \tau)$. Without
loss of generality we can assume that $\tau = 1$. To determine the overall
non-inferiority margin $\varepsilon$, again consider the boundary of the null hypothesis,
i. e. $\text{P}(\widetilde{X}_{0k} < \widetilde{X}_{1l}) = 1/2 - \varepsilon $.

\begin{align*}
\text{P}(\widetilde{X}_{0k}  < \widetilde{X}_{1l}) &= p_0 p_1 \text{P}(T_{0k} < T_{1l}) + p_0 q_1 + q_0 q_1 P(X_{0k} < X_{1l}) \\
                                  &= p_0 p_1 \frac{\lambda_0}{\lambda_0 + \lambda_1} + p_0 (1-p_1)  + (1 - p_0)(1 - p_1)(\frac{1}{2} - \tilde{\varepsilon}) \\
                                  &= \frac{1}{2} - \left( (1-p_0)(1-p_1) \tilde{\varepsilon} + \gamma p_0 p_1 + \frac{1}{2} (p_1 - p_0) \right) \mbox{ with } \gamma = \frac{1}{2} - \frac{\lambda_0}{\lambda_0 + \lambda_1} \\
\intertext{and hence, as $\tilde{\epsilon} = 1/2 - \Phi(-1/\sqrt{8})$,}
 \varepsilon &= (1-p_0)(1-p_1)\tilde{\varepsilon}  + \gamma p_0 p_1 + (p_1 - p_0)/2 \\
             &= (1-p_0)(1-p_1) (1/2 - \Phi(-1/\sqrt{8})) + \gamma p_0 p_1 + (p_1 - p_0)/2
\intertext{For $p_0 = p_1 = p$ this simplifies to}
 \varepsilon &= (1-p)^2 \tilde{\varepsilon} = (1-p)^2 (1/2 - \Phi(-1/\sqrt{8})).
\end{align*}

<<powerplot_untied, fig.lp="fig:", fig.cap = 'Power and sample size for untied case with sample size allocation for reference to new treatment 1:2. In each panel a  different relative risk (RR) of death in the new treatment group (risk $p_1$) compared to the reference group (risk $p_0$) is assumed under the null hypothesis. The power is computed for the alternative of equivalence of both treatments. Different line types correspond to different risks in the reference group.', echo=FALSE, eval=TRUE, out.width='0.8\\linewidth',out.height='0.9\\linewidth'>>=
# source("PowerAndMoments.R") #include functions to compute moments and power
# explore power for specific situation described above, varying the
# probabiliy of death
# sample size in each group
n_0 <- seq(1:150)
n_1 <- 2*n_0

# chosen probabilities of death
chosen_ps <- c(0, 0.01, 0.02, 0.05, 0.1, 0.2)
l_chosen_ps <- length(chosen_ps) # number of chosen probabilities of death

# chosen relative risks (treatment(1)  vs control(0) under H0)
chosen_risks <- c(1, 1.2, 1.75, 2.5)
l_chosen_risks <- length(chosen_risks) # number of chosen risks
figure_elements <- LETTERS[1:l_chosen_risks]

# vector to hold sample sizes
samplesize_80 <- c(rep(NA, l_chosen_ps))
names(samplesize_80) <- as.character(chosen_ps)

# matrix to hold power for all combinations of probabilities of death and sample size
MyPower.Matrix <- matrix(rep(NA, length(n_0)*l_chosen_ps), ncol = l_chosen_ps)
dimnames(MyPower.Matrix)[[2]] <- as.character(chosen_ps)

# vector to hold non-inferiority margins corresponding to chosen situation
epsilon_ps <- c(rep(NA, l_chosen_ps))
names(epsilon_ps) <- as.character(chosen_ps)

# vector of datasets to hold combination of chosen p's, computed epsilon's and sample
# sizes for power 80%
results <- list()

par(mfrow = c(2, 2)) # construct panel of 2x2 graphs, this only works fine if four graphs are produced

for (RR in seq_along(chosen_risks)) {
  for (p in chosen_ps) {
    MyPower <- power_gr(alpha = 0.0294,
                        p_0_0 = p, p_1_0 = chosen_risks[RR]*p, p_0_1 = p, p_1_1 = p,
                        mu_0_0 = 0.3, mu_1_0 = 0.25, mu_0_1 = 0.3, mu_1_1 = 0.3,
                        sigma = 0.1, tau = 1,
                        n_0 = n_0, n_1 = n_1,
                        verbose = FALSE, tied = FALSE)
     MyPower.Matrix[, as.character(p)] <- MyPower$power
     epsilon_ps[as.character(p)] <- MyPower$epsilon
     index <- min(which(MyPower$power >= 0.8))
     samplesize_80[as.character(p)] <- n_0[index] + n_1[index]
  }
  results[[RR]] <- data.frame(chosen_ps, epsilon_ps, samplesize_80)

  # plot power as function of sample size and p
  # first establish empty plot with axes
  plot(NULL, xlab = "Total sample size", ylab = "Power", xlim = c(0, max(n_0) + max(n_1)), ylim = c(0, 1))
  my.lt <- c(1:6)     # define line types for graph
  my.col <- c(grey.colors(l_chosen_ps, start = 0, end = 0.6, gamma = 2.2))
                       # define 'colors' for graph
  # plots for p_0 ^= 0
  for (i in seq_along(chosen_ps[2:l_chosen_ps])) {
    lines(x = n_0 + n_1, y = MyPower.Matrix[, as.character(chosen_ps[i + 1])],
          lwd = 2, lty = my.lt[i + 1], col = my.col[i + 1])
  }
  # plots for p_0 = 0 (black line should always be visible)
  lines(x = n_0 + n_1, y = MyPower.Matrix[, "0"], type = "l", lwd = 2, lty = 1, col = "black")

  legend("bottomright", title = TeX("$p_1 = $ RR $ \\cdot p_0$"),
         legend = as.character(chosen_ps), inset = 0.05, bty = "n", lwd = 2,
         lty = my.lt, col = my.col )
  legend("topleft", legend = figure_elements[RR], cex = 1.5, inset = -0.05, bty = "n")
  title(main = paste0("RR = ", as.character(chosen_risks[RR])))
}
@

In figure \ref{fig:powerplot_untied} the solid black line is identical in all panels; it
depicts the situation when no censoring due to death occurs. Figure
\ref{fig:powerplot_untied}A describes the situation when mortality is the same in both
treatment groups. For given sample size power decreases with an increase in
probability of censoring by death. Figure \ref{fig:powerplot_untied}B also exhibits this
effect, however, here the risk of censoring by death is 20\% higher in the new
treatment group under null hypothesis and the power is less affected by the risk
of censoring by death. If $\lambda_0$ and $\lambda_1$ are such that
$\lambda_0 / (\lambda_0 + \lambda_1) = 1/2 - \tilde{\varepsilon}$ then

\begin{align*}
\text{P}(\widetilde{X}_{0k}  < \widetilde{X}_{1l}) &= p_0 p_1 (1/2 - \tilde{\varepsilon}) + p_0 (1-p_1)  + (1 - p_0)(1 - p_1)(1/2 - \tilde{\varepsilon}) \\
   &= (1/2 - \tilde{\varepsilon})(1 + p_0 - p_1) - 2 \tilde{\varepsilon}p_0 p_1 \\
   &\approx 1/2 - \tilde{\varepsilon} \mbox{ if } p_0, p_1 \ll 1
\end{align*}

This effect can be seen in figure \ref{fig:powerplot_untied}C where the power for the
smaller probabilities for death is very similar to the situation where there is
no censoring by death. In figure \ref{fig:powerplot_untied}D the assumption is that
under the null hypothesis the risk for death ist 2.5 fold in the new treatment
group compared to the reference group. In this case the power increases with
increasing probability of censoring due to death.

\subsection{Tied case}
\label{sec:AppTied}
For the tied case it suffices to make an assumption about the probability of death
in each group under the null hypothesis. To determine the overall non-inferiority margin
we again consider the boundary of the null hypothesis
$\text{P}(\widetilde{X}_{0k}  < \widetilde{X}_{1l}) = 1/2 - \varepsilon $.


\begin{align*}
 \text{P}(\widetilde{X}_{0k}  < \widetilde{X}_{1l}) &= p_0 p_1 / 2 + p_0 q_1 + q_0 q_1 P(X_{0k} < X_{1l}) \\
    &= p_0 - p_0 p_1/2 + (1 - p_0)(1 - p_1)/2 - (1 - p_0)(1 - p_1) \tilde{\varepsilon}\\
    &= 1/2 - (p_1 - p_0)/2 - (1 - p_0)(1 - p_1) \tilde{\varepsilon}
\intertext{and hence, again considering that $\tilde{\epsilon} = 1/2 - \Phi(-1/\sqrt{8})$,}
\varepsilon &= (p_1 - p_0)/2 + (1 - p_0)(1 - p_1) \tilde{\varepsilon} \\
            &= (p_1 - p_0)/2 + (1 - p_0)(1 - p_1) (1/2 - \Phi(-1/\sqrt{8}))
\intertext{For $p_0 = p_1 = p$ this also simplifies to}
\varepsilon &= (1-p)^2 \tilde{\varepsilon} = (1-p)^2 (1/2 - \Phi(-1/\sqrt{8})).
\end{align*}

In table 1 the effective non-inferiority margin $\varepsilon$ for the
Wilcoxon-Mann-Whitney test for non-inferiority and the total number of cases
needed to obtain a power of 80\% at signifcance level $\alpha = 0.0294$ are
shown as function of the probability of death in the reference group $p_0$ and
the relative risk $RR$ of death in the new treatment group compared to the
reference group under $H_0$.
In our example, there is little difference in power between the tied case
and the untied case for given sample size. Specifically, effective
non-inferiority margins and sample sizes are identical in the tied and untied
case if the probability of death is identical in both treatment groups.

\section{Discussion}
\label{sec:Discussion}
In section \ref{sec:Power} we derived power formulae for the Wilcoxon-Mann-Whitney
test for the situation were observations may be censored due to death, relying
on the work of Matsouak and Betensky (2015) for the ordinary Wilcoxon-Mann-Whitney
test in the presence of death censored observations. Both, the untied situation
in which time of death is considered and the tied situation in which all deaths
are ranked identically were considered. While the formulae use approximations,
it can be expected from the simulations by Matsouak and Betensky (2015) that they
give  sufficiently accurate results for practical applications.

We applied the derived formulae to an example from cardiology and found in this
situation that there is little to no difference in power for given sample size
between the tied and untied case.

As expected, power decreases with increasing probability of death -- while the
relative risk in the new treatment group is not too high compared to the reference
group. This effect is most pronounced if the probability of death is identical in
both groups under the non-inferiority null hypothesis.
It decreases with increasing relative risk in the the new treatment group compared
to the reference group. We also observed that sample size and power are hardly
affected by censoring due to death if $\lambda_0/(\lambda_0 + \lambda_1) \approx
1/2 - P(X_0 < X_1)$ where $\lambda_0, \lambda_1$ are the hazards -- given
exponential distribution of time to death -- and $P(X_0 < X_1)$ the probability
that the quantiative outcome tends to smaller values in the reference
distribution. If the relative risk of death in the new treatment group is much
higher relative to the reference group the effects are reversed, i. e. power
increases with increasing probability of death due to censoring. However, allowing
so much higher risk of death as non-inferior does not seem to be a sensible
assumption for clinical trials.

As usual when using any combination of endpoints, there may be conflicting
results, i. e. there may be an advantage of the new treatment with respect to
the quantitative outcome and a disadvantage with respect to death or vice versa.
This possibility needs consideration.

It is questionable whether a joint non-inferiority margin for both, the
probability of death and the quantitative outcome, is appropriate. It is
possible to use separate margins when deriving the power formula. However, in
the end the separate margins will be combined into one overall margin.

Another possibility would be to assign different weights to time to death and
the quantitative outcome such as suggested by Matsouaka et al (2016). This would
allow to prevent to a certain extent to take too high risks of death when the
new treatment is beneficial only with respect to the quantitative endpoint.

However, our focus is on finding an appropriate way of including cases with
missing quantitative outcome due to death in the analyses. In the end, clinical
judgement is necessary and in a clinical trial the two outcomes have to be
carefully assessed if the non-inferiority null hypothesis is rejected.

\begin{thebibliography}{10}

\bibitem[Lachin(1999)Lachin, J. L]{bib1}Lachin, J. L. (1999) Worst-rank score analysis with informatively missing observations in clinical trials.  \textit{Controlled Clinical Trials} \textbf{20}, 408 – 422.

\bibitem[Wittes et al(1989)Wittes, J., Lakatos, E., and Probstfield, J.]{bib2}Wittes, J., Lakatos, E., and Probstfield, J. (1989) Surrogate endpoints in clinical trials: cardiovascular diseases. \textit{Statistics in Medicine} \textbf{8}, 415 – 425.

\bibitem[O'Brien(1984) O'Brien, P. C.]{bib3} O'Brien, P. C. (1984) Procedures for comparing samples with multiple endpoints. \textit{Biometrics} \textbf{40}, 1079 – 1087.

\bibitem[Felker et al(2008) Felker, G. M., Anstrom, K. J., Rogers, J. G.]{bib4} Felker, G. M., Anstrom, K. J., Rogers, J. G. A. (2008) global ranking approach to end points in trials of mechanical circulatory support devices. \textit{Journal of Cardiac Failure} \textbf{14}, 368 – 372.

\bibitem[Felker and Maisel(2010) Felker, G. M., Maisel, A. S.]{bib5} Felker, G. M., Maisel, A. S. (2010) A Global Rank End Point for Clinical Trials in Acute Heart Failure. \textit{Circulation: Heart Failure} \textbf{3}, 643 - 646.

\bibitem[Matsouaka and Betensky(2015) Matsouaka, R. A., Betensky, R. A.]{bib6} Matsouaka, R. A., Betensky, R. A. (2015) Power and sample size calculations for the Wilcoxon–Mann–Whitney test in the presence of death-censored observations. \textit{Statistics in Medicine} \textbf{34}, 406 – 431.

\bibitem[Matsouaka et al (2015) Matsouaka, R. A., Singhal, A. B., Betensky, R. A.]{bib7} Matsouaka, R. A., Singhal, A. B.Betensky, R. A. (2016) An optimal Wilcoxon–Mann–Whitney test of mortality and a continuous outcome. \textit{Statistical Methods in Medical Research} \textbf{epub ahead of print},  doi: 10.1177/0962280216680524.

%\bibitem[]{bib} \textit{} \textbf{}, –.

\end{thebibliography}
%\newpage
\phantom{aaaa}
\end{document}